---
title: "LLM 기반 에이전트 기술 정리"
date: 2025-11-08
desc: "LLM, RAG, MCP를 중심으로 한 최신 AI 에이전트 기술과 미래 전망"
thumbnail: "/posts/ai/ai.jpg"
---

이번 글에서는 <b>대규모 언어 모델(LLM)</b>을 중심으로 **RAG**와 **MCP** 기술을 살펴보고,  
이들이 어떻게 결합되어 <b>행동하는 AI 에이전트</b>를 구현하는지 정리했습니다.

---

## LLM이란 무엇인가?

<b>LLM (Large Language Model)</b>은 대규모 텍스트 데이터를 학습하여 언어를 이해하고 생성할 수 있는 인공지능 모델입니다.  
대표적으로 ChatGPT, Claude, Gemini, Llama 등이 있습니다.

### 주요 특징
- **프롬프트 기반 응답 생성**: 사용자의 자연어 입력(prompt)에 따라 적절한 텍스트를 생성합니다.  
- **광범위한 지식 학습**: 다양한 도메인의 언어 패턴과 지식을 내재화합니다.  
- **맥락 기반 추론**: 단순 암기가 아니라, 문맥을 이해하고 논리적으로 추론할 수 있습니다.

### 활용 예시
- **LangChain**을 이용한 프롬프트 흐름 제어  
- **문서/대화 요약**, **감정 분석**, **질문-응답(Q&A)** 시스템 구축  
- **코드 생성**, **데이터 분석** 등 지능형 업무 자동화

---

## LLM의 한계

LLM은 뛰어난 언어 생성 능력을 가지고 있지만 다음과 같은 근본적인 제약이 있습니다.

| 한계 | 설명 |
|------|------|
| **최신 정보 반영 불가** | 학습 시점 이후의 데이터는 반영되지 않음 |
| **Hallucination(환각 현상)** | 실제 사실과 다르지만 그럴듯한 답변을 생성 |
| **계산·검색·제어 불가** | 외부 도구 사용 불가로 정확한 연산이나 DB 조회 불가 |
| **능동적 실행 불가** | 스스로 행동하거나 시스템을 제어할 수 없음 |

이러한 한계를 보완하기 위해 등장한 기술이 바로 **RAG**와 **MCP**입니다.

---

## RAG (Retrieval-Augmented Generation)

### 정의
**RAG**는 LLM이 사전에 학습되지 않은 정보를 외부 문서에서 검색해 보강한 뒤,  
그 내용을 기반으로 보다 정확한 답변을 생성하는 기술입니다.

### 작동 원리
1. **문서 분할 (Chunking)** – 긴 문서를 여러 조각으로 나눕니다.  
2. **임베딩 생성 (Embedding)** – 각 조각을 벡터(숫자 배열)로 변환해 **벡터 DB**에 저장합니다.  
3. **질문 임베딩 + 검색** – 사용자의 질문을 벡터화하여 의미적으로 유사한 문서를 검색합니다.  
4. **LLM 응답 생성** – 검색된 문서를 **Context**로 입력해 최종 답변을 생성합니다.

### 활용 예시
- 사내 문서 기반 Q&A (규정·정책 질의응답)
- 기술지원 자동화 (FAQ, 제품 매뉴얼)
- EMS 운영정보 검색 (설비, 운전 이력)
- 금융·법률 문서 요약 및 응답
- 의료 지식 검색 및 정리

### 실제 예시
> **질문:** 해외 출장 일당은 어떻게 계산되나요?  
> **응답:** 숙박비와 일비가 등급별 상한액에 따라 지급됩니다.  
> 최고 등급의 경우 숙박비는 180달러, 일비는 120달러로 책정됩니다.  
> 해당 금액을 참고하여 출장비를 계획하시면 됩니다.

---

## MCP (Model Context Protocol)

### 정의
**MCP**는 Anthropic이 제안한 **Open Protocol**로,  
LLM이 외부 시스템과 안전하게 상호작용할 수 있도록 하는 **표준 통신 방식**입니다.

즉, LLM이 **도구를 호출하고**, **작업을 실행하고**, **결과를 받아**  
<b>행동하는 에이전트</b>처럼 동작할 수 있게 만드는 인터페이스입니다.

### 구조
MCP는 다음 두 구성요소로 나뉩니다.

- **MCP Server** – 외부 시스템(예: DB, GitHub, 파일 시스템 등)에 대한 도구를 제공합니다.  
- **MCP Client** – LLM이 MCP 서버의 도구를 호출하여 실제 작업을 수행합니다.

이 구조를 통해 LLM은 다양한 앱, 시스템과 연결되어 **자율적 에이전트**로 확장됩니다.

### 활용 예시
- GitHub 연동 → PR 생성, 이슈 자동 등록  
- Supabase 연동 → 데이터 삽입, 조회, 삭제  
- Vercel 연동 → 자동 배포  
- 파일 시스템 조작 → 파일 목록, 읽기/쓰기 자동화

---

## RAG vs MCP 핵심 비교

| 구분 | RAG | MCP |
|------|-----|-----|
| **핵심 역할** | LLM에 **지식**을 보강 | LLM에 **행동력**을 부여 |
| **기능 초점** | 검색 및 문맥 확장 | 외부 시스템 제어 및 실행 |
| **적용 사례** | 문서 검색형 Q&A | PR 생성, 배포, DB 작업 |
| **결합 시 효과** | 지식형 + 행동형 에이전트 완성 | |

---

## LLM Agent의 3대 구성 요소

1. **Function Calling** – 어떤 함수를 호출할지 판단  
2. **LangChain** – 실행 흐름 제어 (조건, 반복, 메모리 등 관리)  
3. **MCP** – 실제 외부 시스템에서 동작 실행 (API 호출, 배포 등)

이 세 가지가 결합되어야 LLM이 진정한 의미의 **Agent**로 작동할 수 있습니다.

---

## 미래 전망

과거의 LLM이 단순히 질문에 답하는 AI였다면,  
이제는 <b>질문에 답하고, 실제로 행동까지 하는 AI</b>로 진화하고 있습니다.

- 개발자뿐 아니라 **비개발자도 LLM+RAG+MCP 기반으로 업무 자동화**가 가능해집니다.  
- LLM은 회사의 **AI 도구 체계의 중심축**으로 자리잡을 것입니다.  
- RAG는 **정보를 똑똑하게 찾는 도구**, MCP는 **행동하는 도구**로서  
  두 기술이 결합하면 기업 전반의 **자동화 생태계**를 완성할 수 있습니다.

---

## 결론

LLM의 진화는 단순한 언어 모델을 넘어  
<b>지식 검색(RAG)</b>과 <b>행동 실행(MCP)</b>을 결합한 <b>실행형 에이전트</b>로 나아가고 있습니다.

향후 기업은 LLM 에이전트를 통해  
문서 기반 지식관리부터 실시간 자동화까지 폭넓은 업무 혁신을 이룰 것입니다.